---
title: 'nlmeVPC: Visual Model Diagnosis for the Nonlinear Mixed Effect Model'
date: '2023-08-26'
abstract: "A nonlinear mixed effects model is useful when the data are repeatedly
  measured within the same unit or correlated between units. Such models are widely
  used in medicine, disease mechanics, pharmacology, ecology, social science, psychology,
  etc. After fitting the nonlinear mixed effect model, model diagnostics are essential
  for verifying that the results are reliable. The visual predictive check (VPC) has
  recently been highlighted as a visual diagnostic tool for pharmacometric models.
  This method can also be applied to general nonlinear mixed effects models. However,
  functions for VPCs in existing R packages are specialized for pharmacometric model
  diagnosis, and are not suitable for general nonlinear mixed effect models. In this
  paper, we propose \\CRANpkg{nlmeVPC}, an R package for the visual diagnosis of various
  nonlinear mixed effect models. The \\pkg{nlmeVPC} package allows for more diverse
  model diagnostics, including visual diagnostic tools that extend the concept of
  VPCs along with the capabilities of existing R packages. \n"
draft: no
author:
- name: Eun-Hwa Kang
  affiliation: Ewha Womans University
  address: Department of Statistics, Ewha Womans University, Seoul, Korea
- name: Myungji Ko
  affiliation: Ewha Womans University
  address: Department of Statistics, Ewha Womans University, Seoul, Korea
- name: Eun-Kyung Lee
  affiliation: Ewha Womans University
  address: Department of Statistics, Ewha Womans University, Seoul, Korea
  email: lee.eunk@ewha.ac.kr
  orcid: 0000-0003-0817-5000
type: package
output:
  rjtools::rjournal_article:
    self_contained: yes
    toc: no
bibliography: EunKyung_Lee.bib
date_received: '2022-02-24'
volume: 15
issue: 1
slug: RJ-2023-026
journal:
  lastpage: 100
  firstpage: 83

---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(ggplot2)
#library(kableExtra)
```

# Introduction


After fitting a model, diagnosing the fitted model is essential for verifying that the results are reliable [@nguyen2017model]. For linear models, the residuals are usually used to determine the goodness of fit of the fitted model. However, due to random effects and nonlinearity, residuals are less useful for diagnosing fit in nonlinear mixed effects models. Therefore, various diagnostic tools for this type of model have been developed. The nonlinear mixed effect model is useful when the data are repeatedly measured within the same unit, or the relationship between the dependent and independent variables is nonlinear. It is widely used in various fields, including medicine, disease mechanics, pharmacology, ecology, pharmacometrics,  social science, and psychology [@pinheiro2006mixed; @davidian2017nonlinear]. Recently, among the various diagnostic tools applicable to  nonlinear mixed models, simulation-based diagnostic methods have been developed in the field of pharmacology [@karlsson2007diagnosing]. The visual predictive check (VPC; @karlsson2008tutorial) is a critical diagnostic tool that visually tests for the adequacy of the fitted model. It allows for the diagnosis of fixed and random effects in mixed models [@karlsson2008tutorial] in the original data space.
Currently, it is a widely used method for diagnosing population pharmacometric models:
@heus2022model used the VPC method to evaluate their population pharmacokinetic models of vancomycin, @mudde2022predictive checked their final population PK model for each regimen of antituberculosis drug using the VPC method, and @otto2021predictive compares the predictive performance of parent-metabolite models of (S)-ketamine with the VPC method. This VPC method can be used for general nonlinear mixed effect models, including hierarchical models.


The \pkg{psn} [@lindbom2004perl] and \CRANpkg{xpose4} [@keizer2013modeling] packages provide various diagnostic methods for pharmacometric models in R [@R], including the VPC plot. These packages were developed only for the pharmacometricians, and the users needed to use the NONMEM software [@bauer2011nonmem] for generating inputs of functions in these two packages. However, NONMEM is licensed software, and it is mainly designed towards the analysis of population pharmacometric models. Therefore, it is not easy for nonpharmacometrician to use NONMEM and to draw the VPC plot through \pkg{psn} and \pkg{xpose4}. Recently, the \CRANpkg{vpc} [@keizer2018vpc]  package and \CRANpkg{nlmixr2} [@fidler2019nonlinear]  package have been developed to draw VPC plots in R without  results from NONMEM. However, \pkg{vpc} package provides the function for drawing the original VPC plot only. \pkg{nlmixr2} was developed initially for fitting general dynamic models. To check the fitted model, \pkg{nlmixr2} provides a function to use graphical diagnostics in \pkg{xpose4} with the `nlmixr2` model object. Also, \pkg{nlmixr2} uses the VPC plot in the \pkg{vpc} package with the `nlmixr2` model object. Therefore, both packages only provide a function to draw the basic VPC plot, and the other newly developed simulation-based methods, including extensions of VPC, are not provided.

We have developed a new R package, \pkg{nlmeVPC}, to provide a suite for various visual checking methods for the nonlinear mixed models. This package includes various state-of-the-art model diagnostic methods based on the visual comparison between the original and simulated data. Most methods compare the statistics calculated from the observed data to the statistics from the simulated data. Percentiles, for example, the $10^{th}$, $50^{th}$, and $90^{th}$ percentiles, are widely used to summarize relevant statistics from the observed and simulated data. We compare the similarities between the statistics from the observed data and those from the simulated data in two different spaces: the data space and the model space [@wickham2015visualizing]. The original data comprise the data space. Usually, the data space is represented by the independent and dependent variables, such as time and blood concentration, in the pharmacokinetic data. On the other hand, the model space is composed of quantities obtained from the fitted model, for example, residuals and summary values from the fitted model. From this viewpoint, we categorize the well-known visual diagnostic tools into two categories. One method compares the observed and simulated data in the original data space, and the other in the model space. In the method with the data space, we developed functions for the original VPC (`VPCgraph`), the additive quantile regression VPC (`aqrVPC`), and the bootstrap VPC (`bootVPC`). In addition, we proposed a new VPC method: the average shifted VPC (`asVPC`). In the method with the model space, the coverage plot (`coverageplot`) and the quantified VPC (`quantVPC`) are included. For a more detailed diagnosis, we developed a coverage detailed plot (`coverageDetailplot`). In \pkg{nlmeVPC}, the \CRANpkg{ggplot2} package [@ggplot2Hadley2nd] is used to create all plots.


# Nonlinear mixed effect model

The general nonlinear mixed effect model is defined as follow:
$$
y_{ij} = f(x_{ij}, \theta, \eta_i, \epsilon_{ij}) \\
\eta_i \sim N(0,\Omega) \nonumber\\
\epsilon_{ij}  \sim N(0, \Sigma)\nonumber
$$
where $y_{ij}$ is the dependent variable of the $j^{th}$ observation of the $i^{th}$ individual, $x_{ij}$ is the independent variable, $f$ is the nonlinear function of $x_{ij}$, $\theta$ is the population parameter, $\eta_i$ represents the variability of the individual $i$, and $\epsilon_{ij}$ represents the random error. From the data, $\theta$ , $\Omega$, and $\Sigma$ are estimated. For the simulated data, the fitted model $y_{ij} = f(x_{ij}, \hat{\theta}, \eta_i, \epsilon_{ij})$,  $\eta_i \sim N(0,\hat\Omega)$, $\epsilon_{ij}  \sim N(0, \hat\Sigma)$ are used.

# Validation in the data space

The VPC is the most popular model validation method in the pharmacometrics area. It was developed to diagnose population pharmacokinetic/pharmacodynamic models visually.
The main idea of the VPC is to compare the distribution of observations and the distribution of predicted values, where the distribution of predicted values is obtained from simulated data drawn from the fitted model. If the fitted model explains the observed data well, these two distributions should be similar.
Both distributions can be represented in the original data space that consists X axis as the independent variable and Y axis as the dependent variable.
It allows us to compare the observed data with the fitted model in the original data space. In \pkg{nlmeVPC}, we include an original VPC plot, an additive quantile regression VPC [@jamsen2018regression], and a bootstrap VPC [@post2008extensions]. We also proposed a new approach to draw the VPC: the average shifted VPC.

## Visual Predictive Check

The visual predictive check (VPC; @karlsson2008tutorial) is based on the principle that if the fitted model adequately describes the observed data, the distribution of the simulated data from the fitted model should be similar to the distribution of the observed data. There are several ways to compare the similarities between the distributions. In the VPC approach, profiles of quantiles are used. Two profiles are mainly used to compare the distributions of observations and predictions. One profile is from the upper bound of the prediction intervals, and the other is from the lower bound. These prediction intervals are calculated from the simulated data. 90$\%$ prediction intervals are usually used. For small and sparse samples, 80$\%$ prediction interval is also used. The lower and upper bounds of 80$\%$ prediction interval are the $10^{th}$ and $90^{th}$ percentiles of the simulated data. Figure \@ref(fig:Fig0)(A) shows the "scatter" type of the VPC plot. Dots indicate the observed data. Two dashed blue lines represent profiles of the $10^{th}$ and $90^{th}$ percentiles of the simulated data, and the solid blue line represents the $50^{th}$ percentile. If the fitted model represents the observed data well, most observed data should lie between profiles of $10^{th}$ and $90^{th}$ percentiles.


Figure \@ref(fig:Fig0)(B) is the "percentile" type of the VPC plot. In this plot, profiles of percentiles from the observed data are compared to profiles of percentiles from the simulated data. Two dashed red lines represent profiles of the $10^{th}$ and $90^{th}$ percentiles of the observed data, and the solid red line represents profiles of the $50^{th}$ percentile of the observed data. If the fitted model represents the observed data well, two profiles in each percentile - one from the original data and the other from the simulated data - are similar. 

Figure \@ref(fig:Fig0)(C) is the "CI" type of the VPC plot. The solid red line represents the $50^{th}$ percentile of the observed data, and dashed red lines represent the $10^{th}$ and $90^{th}$ percentiles of the observed data. Light blue areas represent the 95$\%$ confidence areas of the $10^{th}$ and $90^{th}$ percentiles, and pink areas represent the 95$\%$ confidence areas of the $50^{th}$  percentile. These confidence areas were calculated from the simulated data. After calculating percentiles in each simulated data, we find 95$\%$ confidence intervals for each percentile and use this to draw the areas. In this plot, it is necessary to verify that the profiles of the original data are in confidence areas of each profile from the simulated data in each percentile. If each percentile line of the observed data is in the corresponding confidence area, this can be evidence
that the fitted model represents the observed data quite well. Otherwise, the fitted model needs to be improved. The "CI" type of the VPC plot is the most widely used type in pharmacometrics.

The percentiles of the dependent variable are calculated in each bin. To estimate the percentiles accurately, enough data points need to lie within each bin. No binning means that the number of bins is equal to the number of different independent variable values. In this case, the VPC plot shows all details of the relationship between the independent and dependent variables. However, the resulting lines become too irregular to show meaningful trends or patterns.
 
As the number of bins decreases, the lines become smoother and more regular, however this can come at the loss of information if too much smoothing is used. Therefore, the selection of the best number of bins is crucial. The way of determining cutoffs for bin also plays an important role.  @lavielle2011automatic proposed a procedure for finding the optimal bin configuration automatically, including the optimal number of bins and the optimal bin cutoffs.
`VPCgraph` provides the automatic binning with `optK` and `makeCOVbin`; here, `optK` finds the optimal number of bins, and `makeCOVbin` finds the optimal cutoffs of bins using Lavielle and Bleakley's method.


```{r Fig0, fig.height = 12, fig.width=8, fig.cap = "The visual predictive check plot. The solid red line represents the $50^{th}$ percentile of the observed data, and dashed red lines represent the $10^{th}$ and $90^{th}$ percentiles of the observed data. The solid blue line represents the $50^{th}$ percentile of the simularted data, and dashed blue lines represent the $10^{th}$ and $90^{th}$ percentiles of the simulated data. Light blue and pink areas represent the 95% confidence areas of the $10^{th}$, $50^{th}$ and $90^{th}$ percentile lines."}
library(nlmeVPC)
library(ggplot2)
library(gridExtra)
data(origdata)
data(simdata)

A=VPCgraph(origdata,simdata,N_xbin=8,type="scatter")+
  labs(title="(A) Visual Predictive Check : scatter",caption="")
B=VPCgraph(origdata,simdata,N_xbin=8,type="percentile")+
  labs(title="(B) Visual Predictive Check : percentile",caption="")
C=VPCgraph(origdata,simdata,N_xbin=8,type="CI")+
  labs(title="(C) Visual Predictive Check : CI",caption="")
grid.arrange(A,B,C,nrow=3)
```

## Additive quantile regression VPC

To overcome the difficulties of making bins as well as determining the number of bins,
@jamsen2018regression used additive quantile regression to calculate the quantiles of the observed and simulated data. This regression method makes it possible to estimate quantiles without discrete binning, which is especially useful when the data are insufficient, irregular, or inappropriate to configure the bins. To fit the additive quantile regression, we used  the `rqss` function in the \CRANpkg{quantreg} [@quantreg] package and developed the `aqrVPC` function to draw the VPC type plot with additive quantile regression. Figure \@ref(fig:Fig1) shows the additive quantile regression VPC plot. The solid and dashed lines represent the $10^{th}$, $50^{th}$, and $90^{th}$ additive quantile regression lines of the observed data, and the pink and light blue areas represent the confidence areas of the additive quantile regression lines of the simulated data. Lines and areas in the additive quantile regression VPC plot are much smoother than those in the original VPC plot.


```{r Fig1, fig.height = 4, fig.width=8, fig.cap = "The additive equantile VPC plot.  Dots indicate the observed data. The solid and dashed blue lines represent the $10^{th}$, $50^{th}$, and $90^{th}$ percentiles of the simulated data. The solid red line represents the $50^{th}$ percentile line. Light blue and pink areas represent the 95% confidence areas of the $10^{th}$, $50^{th}$ and $90^{th}$ percentile lines."}
aqrVPC(origdata,simdata) +labs(caption="")
```

## Bootstrap VPC

The bootstrap VPC [@post2008extensions] compares the distribution of the simulated data to the distribution of the bootstrap samples drawn from the observed data.
This plot reflects the uncertainty of the observed data and allows for more objective comparisons with the predicted median.

Figure \@ref(fig:Fig2) shows the bootstrap VPC plot using `bootVPC`.  The solid and dashed blue lines represent the $10^{th}$, $50^{th}$, and $90^{th}$ percentiles of the simulated data. The solid red line represents the $50^{th}$ percentile line, and the pink areas represent the 95$\%$ confidence areas of the $50^{th}$ percentile line, calculated from the bootstrap samples of the observed data. If the solid blue line and the solid red line are similar, the solid blue line is in the pink area, and the pink area is located between two dashed blue lines,
then this is evidence that the fitted model fit the observed data well.

```{r Fig2, fig.height = 4, fig.width=8, fig.cap = "The bootstrap VPC plot. Dots indicate the observed data. The solid and dashed blue lines represent the $10^{th}$, $50^{th}$, and $90^{th}$ percentiles of the simulated data. The solid red line represents the $50^{th}$ percentile line, and the pink areas represent the 95% confidence areas of the $50^{th}$ percentile line, calculated from the bootstrap samples of the observed data."}
bootVPC(origdata,simdata,N_xbin=8)
```

## Average shifted VPC

Even though binning mitigates the problem with highly irregular data, the VPC plot still has a precision problem with sparse data. In this paper, we propose a new approach to draw the adapted VPC plot from the average shifted histograms [@scott1985ash].
A histogram is a widely used method for displaying the density of a single continuous variable. However, histograms can look quite different based on different choice of bin width and anchor.
This requires computing an optimal bin width.
To overcome the problem with the choice of bin width and to obtain smoother estimates,  @scott1985ash proposed the averaged shifted histogram (ASH). The idea behind ASH is to make $K$ different histograms with different anchors and to combine them via a weighted average. For each histogram, the starting point is shifted by $d/K$, where $d$ is the width of the bin. We extend this idea to the VPC graph and propose the average shifted visual predictive check (asVPC) plot.

The binning of the VPC varies from the traditional binning in a histogram. The width of the bins is determined such that each bins contains the same, fixed number of observations, and as such the width of each bin is different. To apply the ASH idea to the VPC, we divide our data into $K*B$ bins along with the independent variable, where each bin has a different width but the same number of observations. Here, $B$ is the number of the original bins in the VPC plot, and $K$ is the number of the histograms averaged in the asVPC plot.

To draw the VPC plots, the following information is needed from each bin:

(A) the median of the independent variable and percentiles of the dependent variable of the observed data.

(B) the median of the independent variable and percentiles of the dependent variable of the simulated data.

(C) 95$\%$ confidence interval of percentiles (usually $10^{th}$, $50^{th}$, and $90^{th}$ percentiles) of the dependent variable, calculated from the simulated data.

These values are also needed to produce confidence areas and percentile lines in the asVPC plot. Furthermore, additional steps are needed for asVPC. To find the median of the independent variable and percentiles of the dependent variable using the ASH algorithm, the following procedures are needed:

1. Divide the independent variable into $N=K*B$ bins.

2. For $i = 1, \cdots, N$,
    a) If $i < K$, combine $bin_1, \cdots, bin_{i+K-1}$\\
       else if  $K\le i\le N-K$ , combine  $bin_{i-K+1}, \cdots, bin_{i+K-1}$\\
       else if  $N-K < i$ , combine $bin_{i-K+1}, \cdots, bin_N$
    b) Calculate the median of the independent variable and the weighted percentiles of the dependent variable in the combined bin
    
3. Collect the medians of the independent variable and the weighted percentiles of the dependent variable from 2, and connect them to the lines.


We can implement (A) and (B) by applying these procedures separately to the observed and simulated data. Additionally, (C) can be implemented using these procedures for each simulated dataset. First, we find the weighted percentiles, combine the results from each simulated dataset, and then calculate the 95$\%$ confidence intervals of each percentile. Using these three quantities (A), (B), and (C), we can draw the VPC type plot with the ASH approach, producing the asVPC plot.

### Determining the weights

In the asVPC plot, the observations in each bin are combined using weights. Typically, the data near the center of the integrated bin have higher weights, and the data far from the center have smaller weights. This idea is used in the ASH algorithm as well as the density estimation literature. We suggest two different ways to apply weights for the asVPC calculation.


* Bin-related weight: For each bin in the combined bin, K-1 bins in both directions have weights and the other bins have no weight. Use $\frac{1}{K}$, $\cdots$, $\frac{i-1}{K}$, $\cdots$, $\frac{K-1}{K}$, $1$, $\frac{K-1}{K}$, $\cdots$, $\frac{i-1}{K}$, $\cdots$, $\frac{1}{K}$ as weights for 2K-1 bins. This approach is the same as the original ASH approach.

* Distance-related weight: Use the reciprocal of the distance from the center of the independent variable in each combined bin so that the points near the center have higher weights and the points far from the center have lower weights.


Figure \@ref(fig:Fig3) shows the results from the `asVPC` function using bin-related weights and distance-related weights. The solid and dashed lines represent the average shifted quantile lines of the observed data, and the pink and light blue areas represent the confidence areas of the simulated data. The lines in the asVPC plot are smoother than those in the original VPC plot, and the confidence areas in the asVPC plot are thinner than those in the original VPC plot.


```{r Fig3, fig.height = 8, fig.width=8,fig.cap = "The average shifted VPC plot. Dots indicate the observed data. The solid line represents the 50th quantiles of the observed data, and dashed lines represent the $10^{th}$ and $90^{th}$ percentiles of the observed data. Light blue and pink areas represent the 95% confidence areas of the $10^{th}$, $50^{th}$, and $90^{th}$ percentiles."}
A=asVPC(origdata,simdata,type="CI",N_xbin=8,N_hist=3,weight_method="bin") +labs(caption="")
B=asVPC(origdata,simdata,type="CI",N_xbin=8,N_hist=3,weight_method="distance")+labs(caption="")
grid.arrange(A,B,nrow=2)
```

# Validation in the model space

To validate the fitted model in the model space, we need to choose appropriate statistics to visualize and describe them in the model space. In \pkg{nlmeVPC}, we use the same statistics, that is quantiles, as the VPC plot in the data space, and compare them in two ways - numerically and visually. The numerical predictive check and the coverage plot are two commonly used methods in pharmacometrics. However, there is a limitation to detecting the illness of the fitted model. These methods combine the results of all ranges of the independent variable, and it is helpful to see the overall fitness. However, it is not easy to detect the detailed discrepancy between the fitted model and the observed data. To overcome this limitation, we developed a new plot, the coverage detailed plot, to compensate for the shortness of the coverage plot.

## Numerical predictive check

The VPC plot visually compares the observed data to the simulated percentiles in the data space. On the other hand, the numerical predictive check (NPC; @wang2012standardized; @karlsson2007diagnosing)
numerically compares the observed data to the simulated data. For a given level of prediction (for example, 90$\%$), the predicted interval is calculated using the simulated data, and the number of the observed data points outside of the prediction interval is counted, both below the lower bound and above the upper bound. The expected number of points below the lower bound of the predicted interval (for example, 5$\%$ of observations) is also calculated and compared to the observed number. If these two numbers are similar, the suggested model is suitable [@maharaj2019pitfalls]. 

`NumericalCheck` provides information summarizing the results of the NPC for various prediction levels.
 `PI` is the prediction level $\times$ 100 and `n` is the number of observations.
`"Expected points below PI"` and `"Expected points above PI"` are respectively the expected numbers below and above the PI; `"points below PI"` and `"points above PI"` respectively represent the numbers of points below and above the PI;
`"95%CIBelowFrom(%)"` and `"95%CIBelowTo(%)"` represent the 95$\%$ confidence interval of `"points below PI(%)"`; and `"95%CIAboveFrom(%)"` and `"95%CIAboveTo(%)"` represent the 95$\%$ confidence interval of `"points above PI(%)"`. If `"points below PI(%)"` is in the
95$\%$ confidence intervals of `"points below PI(%)"` and is similar to `"Expected points below PI"`, and if
  `"points above PI(%)"` is in the
95$\%$ confidence intervals of `"points above PI(%)"` and is similar to `"Expected points above PI"`, this is the evidence that the fitted model explains the data well.

```{r echo=TRUE}
NumericalCheck(origdata,simdata,pred.level=c(0,0.2,0.4,0.6,0.8,0.9),N_xbin=8)$NPC
```

## Coverage plot

 The result of the NPC is a table with many values, which, while useful, can be difficult to parse visually. The coverage plot [@karlsson2008tutorial] was developed to help visually check the fitted model with the NPC result.
In each level of the predicted interval, the ratios between the expected number of data points (Exp) outside the prediction interval and the observed number of data  points (Obs)
outside the prediction interval are calculated. These ratios are calculated separately for the upper and lower bound of the prediction interval. For example, when the prediction level is 90, a 90$\%$ prediction interval is used, and 10$\%$ of the observations are expected to locate outside this prediction interval. To be more precise, 5$\%$ of observations are expected to be above the upper limit, and 5$\%$ of observations are expected to be below the lower limit.

The coverage plot with the NPC result can diagnose a model using multiple prediction intervals. The X-axis represents the prediction level, and the Y-axis represents Obs/Exp. The closer Obs/Exp is to 1, the more appropriate the model is. Furthermore, the confidence intervals of Obs/Exp values are obtained using simulated data and then expressed together in the plot for a more objective comparison. This plot can provide more information than the VPC plot, which interprets only a couple of quantiles - usually the 10$\%$, 50$\%$, and 90$\%$ percentiles.

The \pkg{xpose4} package [@keizer2013modeling] provides a coverage plot. However,
to draw the coverage plot using \pkg{xpose4}, PsN [@lindbom2004perl] software is needed to calculate  the NPC result. Therefore, we developed `coverageplot` to draw the coverage plot using the results from `NumericalCheck`.

Figure \@ref(fig:Fig4)(A) shows the coverage plot. The X-axis shows the level of the prediction interval. The Y-axis show the ratio between the observed number of data and the expected number of data of the lower and upper parts in each level of the prediction interval. The white line is the reference line, and the gray area represents the confidence areas of the ratios in each prediction level. If the solid lines are near the white line or in the gray area, we can conclude that the suggested model is suitable.

## Coverage detailed plot

Unlike the VPC plot, which represents the data space, the information in the observed data space does not come together in the coverage plot, which makes it difficult to determine whether the model is overestimated, underestimated, or adequate in the specific region of the data space. To overcome this limitation of the coverage plot, we propose a new method called the coverage detailed plot.
 The percentages of observations above the prediction interval are calculated in each bin of the independent variable. Additionally, the percentages of observations below the prediction interval are calculated. The white dots in the plot represent the expected percentages. If the percentages of upper and lower observations are near the white dots,  we can conclude that the suggested model is suitable for the specific prediction interval.

Figure \@ref(fig:Fig4)(B) is the result of `coverageDetailplot` when the prediction level is 80$\%$. The white dots represent the expected percentages of the lower and upper the prediction intervals, 10$\%$, and 90$\%$, respectively. The upper and lower percentages of observation in each time bin are shown in darker gray. The left bin(before 0.045 hours) shows all light gray in the coverage detailed plot, and it is quite different patterns from the expected one. However, it is mainly due to the characteristics of this example data. All observations in this bin are 0. It makes the lower and upper bound of the prediction interval all 0, and the lower and upper percentages become 0.


```{r Fig4, fig.height = 10, fig.width=6, fig.cap = "The coverage plot and the coverage detailed plot for the 80% prediction interval. In the coverage plot, the X-axis is the level of the prediction interval. The Y-axis is the ratio between the number of observed data and the number of expected data of the lower and upper parts in each level of the prediction interval. The white line is the reference line, and the gray area represents the confidence area of the ratios. If the solid lines are near the white line, we can conclude that the suggested model is suitable. In the coverage detailed plot, the white dots represent the expected percentages of lower and upper prediction intervals of, 10%, and 90%, respectively. The upper and lower percentages of observation in each time bin are darker gray."}

A=coverageplot(origdata,simdata,N_xbin=8) +ggtitle("(A) Coverage Plot")
B=coverageDetailplot(origdata,simdata,N_xbin=8,predL=0.8) +
ggtitle("(B) Coverage detailed plot: PI = 80")
grid.arrange(A,B,nrow=2)
```


## Quantified VPC

@post2008extensions proposed the quantified VPC (QVPC). It expanded the existing VPC, including information about missing data.
The QVPC plot visually represents actual and unavailable observations around the predicted medians through the form of percent, regardless of the observed data's density or shape. Here, "unavailable observations" refer to all kinds of missing values and unobserved data that occur for various reasons, including deviations and unexpected omissions.

If the model is appropriate, observations at each time bin are allocated randomly around the predicted median of the model. In the QVPC plot, white dots represent the model's predicted median in each bin. If the borderlines above and below are close to the white dots, we can conclude that the fitted model describes the observed data well.

Figure \@ref(fig:Fig5) shows the result of `quantVPC`.  The darker gray areas represent the percentages below the median. The lighter gray areas represent the percentage above. The brightest gray areas represent the percent unavailable in each time bin. The white dots represent the ideal location where the above and the below percentages meet. In this example, there is no missing value.


```{r Fig5, fig.height = 5, fig.width=6,fig.cap = "The quantified VPC plot. The darker gray areas represent the percentages below the median, the lighter gray areas represent the percentage above, and the brightest gray areas represent the percent unavailable in each time bin. The white dots represent the ideal location where the above and the below percentages meet."}

quantVPC(origdata,simdata)
```




```{r table1, eval = knitr::is_html_output()}
AA=data.frame(Function = c("VPCgraph","aqrVPC","bootVPC","asVPC","NujmericalCheck","coverageplot","coverageDetailplot","quantVPC"),
           Description = c("draw the original VPC plot",
"draw the additive quantile regression VPC plot",
"draw the bootstrap VPC plot",
"draw VPC using ASH method",
"calculate the numbers to check coverage in each prediction level",
"plot the result of NumericalCheck",
"plot for checking specific prediction level",
"plot for the quantified VPC"))

knitr::kable(AA, format = "html", caption = "List of functions to check the validity of model with the observed data and the simulated data")
```



```{r table2, eval = knitr::is_html_output()}
BB=data.frame(
  Argument =c("orig_data","sim_data","type","weight_method","N_xbin",
"probs","conf.level","X_name","Y_name","subject_name","MissingDV",
"DV_point","CIvpc_type","bin_grid","plot_caption","plot_flag","linesize",
"pointsize","captionsize","maxK","Kmethod","beta","lambda"),
Description=c(
"A data frame of original data with X and Y variable",
"A matrix of simulated data with only Y values collected",
"Type of VPC graph; 'CI', 'percentile', or 'scatter'",
"The way to put weights in `asVPC`; 'bin' or 'distance'",
"Number of bins in X variable",
"A numeric vector of probabilities",
"Confidence level of the interval",
"Name of X variable in`orig_data`",
"Name of Y variable in `orig_data`",
"Name of subject variable in `orig_data`",
"Name of missing indicator variable in `orig_data`",
"Draw point (X, Y) in the plot if TRUE; omit if FALSE",
"Type of CI area in VPC graph; 'line' or 'segment'",
"Draw grid lines for binning in X variable if TRUE; omit if FALSE",
"Put caption with additional information if TRUE; omit if FALSE",
"Draw plot if TRUE; generate data for drawing plot if FALSE",
"Size of line in the plot",
"Size of point in the plot",
"Size of caption",
"The maximum number of bins",
"The way to calculate the penalty in automatic binning; 'cluster' or 'kernel'",
"Additional parameter for automatic binning, used in `optK` function",
 "Additional parameter for automatic binning, used in `optK` function"))


knitr::kable(BB, format = "html", caption = "Summary of the arguments of functions in nlmeVPC")
```


# The nlmeVPC package: structure and functionality


Table \@ref(tab:table1) shows the list of functions and Table \@ref(tab:table2) shows the list of arguments used in the functions of \pkg{nlmeVPC}. The following codes are for Figure \@ref(fig:Fig0) to Figure \@ref(fig:Fig5).

```{r echo=TRUE}
library(nlmeVPC)
data(origdata)
data(simdata)

optK(origdata$TIME)$K
```

```{r echo=TRUE, eval=FALSE}
# Figure 1

VPCgraph(origdata,simdata,N_xbin=8,type="scatter")+
  labs(title="(A) Visual Predictive Check : scatter",caption="")
VPCgraph(origdata,simdata,N_xbin=8,type="percentile")+
  labs(title="(B) Visual Predictive Check : percentile",caption="")
VPCgraph(origdata,simdata,N_xbin=8,type="CI")+
  labs(title="(C) Visual Predictive Check : CI",caption="")
  
# Figure 2

aqrVPC(origdata,simdata) +labs(caption="")

# Figure 3

bootVPC(origdata,simdata,N_xbin=8)+labs(caption="")
 
# Figure 4

asVPC(origdata,simdata,type="CI",N_xbin=8,N_hist=3,weight_method="bin")+labs(caption="")
asVPC(origdata,simdata,type="CI",N_xbin=8,N_hist=3,weight_method="distance")+labs(caption="")
  
# Numerical Predictive Check
 
NumericalCheck(origdata,simdata,N_xbin=8,pred.level=c(0,0.2,0.4,0.6,0.8,0.9))$NPC

# Figure 5
 

coverageplot(origdata,simdata,N_xbin=8) +ggtitle("(A) Coverage Plot")
coverageDetailplot(origdata,simdata,N_xbin=8,predL=0.8) +
ggtitle("(B) Coverage Detailed plot: PI = 80")
 
# Figure 6
 
quantVPC(origdata,simdata)
```



We use an example to show how to use functions in \pkg{nlmeVPC} and how they work.

## Example

The `origdata` in \pkg{nlmeVPC} is from an experiment on the pharmacokinetics of theophylline. Twelve patients were given oral doses of theophylline, and blood concentrations were measured at 11 time points over the next 25 hours. Each patient had different time points.
We consider the following first-order absorption one-compartment model:

$$
y_{ij}= \frac{Amt_i * Ke_i *Ka_i}{Cl_i} \left(\exp( -Ke_i * TIME_{ij})-\exp(-Ka_i * TIME_{ij})\right) +\varepsilon_{ij}.
$$

In this model, $y_{ij}$ is the theophylline concentration at $TIME_{ij}$ after an initial dose of $Amt_i$. The pharmacokinetic parameters are the absorption rate constant $Ka$, the elimination rate constant $Ke$, and the clearance $Cl$.
In this example, two different models are fitted and diagnosed using functions in the \pkg{nlmeVPC} package. In Model 1, $Ka$ and $Cl$ are considered as random effects. In Model 2, $Ke$ is considered as random effect, and $Ka$ and $Cl$ are considered only as a fixed effect. The \CRANpkg{nlme} [@nlme] and \CRANpkg{nlraa} [@nlraa]  packages are used to fit the nonlinear mixed models and to generate the simulated data from the fitted model.


```{r echo=TRUE, eval=FALSE}
library(nlme)
library(nlraa)
library(nlmeVPC)
data(origdata)
origdataT <- groupedData(DV~TIME|ID,origdata)

# Model 1 (True) 
T.nlme <- nlme(DV ~ exp(lKe+lKa-lCl)*AMT*
               (exp(-exp(lKe)*TIME) - exp(-exp(lKa)*TIME))/
               (exp(lKa)-exp(lKe)), data=origdataT,
             fixed=lKa+lKe+lCl~1,
             random=lKa+lCl~1,
             start=c(lKe=-2,lKa=1.5,lCl=-3))
set.seed(123456)
sim.T <- simulate_nlme(object=T.nlme,nsim=100,psim=3,level=1,value="data.frame",data = NULL)
simdata.T <- matrix(sim.T$sim.y,ncol=100)

# Model 2 (Wrong)
F.nlme <- nlme(DV ~ exp(lKe+lKa-lCl)*AMT*
                (exp(-exp(lKe)*TIME) - exp(-exp(lKa)*TIME))/
                (exp(lKa)-exp(lKe)), data=origdataT,
              fixed=lKa+lKe+lCl~1,
              random=lKe~1,
              start=c(lKe=-2,lKa=1.5,lCl=-3))

sim.F <- simulate_nlme(object=F.nlme,nsim=100,psim=3,level=1,value="data.frame",data = NULL)
simdata.F <- matrix(sim.F$sim.y,ncol=100)
```


```{r echo=TRUE, eval=FALSE}
  
# Figure 7
 
VPCgraph(origdata,simdata.T,type="CI",N_xbin=8)+labs(title="Model 1",caption="")
VPCgraph(origdata,simdata.F,type="CI",N_xbin=8)+labs(title="Model 2",caption="")
  
# Figure 8
 
aqrVPC(origdata,simdata.T)+labs(title="Model 1",caption="")
aqrVPC(origdata,simdata.F)+labs(title="Model 2",caption="")
  
# Figure 9
 
asVPC(origdata,simdata.T,type="CI",weight_method="distance",N_xbin=8)+labs(title="Model 1",caption="")
asVPC(origdata,simdata.F,type="CI",weight_method="distance",N_xbin=8)+labs(title="Model 2",caption="")

# Figure 10
 
bootVPC(origdata,simdata.T,N_xbin=8)+labs(title="Model 1",caption="")
bootVPC(origdata,simdata.F,N_xbin=8)+labs(title="Model 2",caption="")
  
# Figure 11
 
coverageplot(origdata,simdata.T,conf.level=0.9,N_xbin=8)+labs(title="Model 1")
coverageplot(origdata,simdata.F,conf.level=0.9,N_xbin=8)+labs(title="Model 2")
  
# Figure 12
 
coverageDetailplot(origdata,simdata.T,predL=0.5,N_xbin=8)+labs(title="Model 1")
coverageDetailplot(origdata,simdata.F,predL=0.5,N_xbin=8)+labs(title="Model 2")
  
# Figure 13
 
coverageDetailplot(origdata,simdata.T,predL=0.8,N_xbin=8)+labs(title="Model 1")
coverageDetailplot(origdata,simdata.F,predL=0.8,N_xbin=8)+labs(title="Model 2")
  
# Figure 14
 
quantVPC(origdata,simdata.T,N_xbin=8)+labs(title="Model 1")
quantVPC(origdata,simdata.F,N_xbin=8)+labs(title="Model 2")

```



Figure \@ref(fig:M11) shows the `VPCgraph` for Model 1 and Model 2.
The solid line represents the 50$^{th}$ percentile of the observed data, and the dashed lines represent the 10$^{th}$ and 90$^{th}$ percentiles of the observed data. In Model 1, all quantile lines (the solid and dashed lines) are in the confidence area. However, the 10$^{th}$ and 90$^{th}$ percentiles in Model 2 are mostly outside the confidence area, especially at 0 to 5 hours.

```{r M11,fig.height = 3, fig.width=7.5,fig.cap = "The VPC plots of Model 1 and Model 2."}
simdata.T=readRDS("./data/simdataT.rda")
simdata.F=readRDS("./data/simdataF.rda")
A=VPCgraph(origdata,simdata.T,type="CI",N_xbin=8)+labs(title="Model 1",caption="")
B=VPCgraph(origdata,simdata.F,type="CI",N_xbin=8)+labs(title="Model 2",caption="")
grid.arrange(A,B,ncol=2)
```


Figure \@ref(fig:M12) shows the results of `aqrVPC`, and Figure \@ref(fig:M13) shows the results of `asVPC` for Model 1 and Model 2. The additive quantile regression VPCs and the average shifted VPCs show similar patterns to the original VPCs. Model 1 shows all quantile lines in the confidence area, and the 10$^{th}$ and 90$^{th}$ percentiles in Model 2 are mostly outside the confidence area.


```{r M12, fig.height = 3, fig.width=7.5,fig.cap = "The additive quantile regression VPC plots for Model 1 and Model 2."}
A=aqrVPC(origdata,simdata.T)+labs(title="Model 1",caption="")
B=aqrVPC(origdata,simdata.F)+labs(title="Model 2",caption="")
grid.arrange(A,B,ncol=2)
```


```{r M13, fig.height = 3, fig.width=7.5,fig.cap = "The average shifted VPC plots for Model 1 and Model 2."}
A=asVPC(origdata,simdata.T,type="CI",weight_method="distance",N_xbin=8)+labs(title="Model 1",caption="")
B=asVPC(origdata,simdata.F,type="CI",weight_method="distance",N_xbin=8)+labs(title="Model 2",caption="")
grid.arrange(A,B,ncol=2)
```


Figure \@ref(fig:M14) shows the results of `bootVPC` for Model 1 and Model 2. The solid and dashed blue lines show the $10^{th}$, $50^{th}$, and $90^{th}$ percentiles of the simulated data. The solid red line represents the $50^{th}$ percentile line of the observed data, and the pink areas represent the 95$\%$ confidence areas of the $50^{th}$ percentile line, calculated from the bootstrap samples of the observed data.
The solid blue line is in the pink area, and the two solid red and blue lines are almost identical in both models.
The dashed blue lines in Model 1 cover most of the observed data. However, the dashed blue lines in Model 2 do not cover the observed data. Many observed data points lie outside these dashed blue lines in Model 2, especially in 0 to 10 hours.

```{r M14, fig.height = 3, fig.width=7.5,fig.cap = "The bootstrap VPC plots for Model 1 and Model 2."}
A=bootVPC(origdata,simdata.T,N_xbin=8)+labs(title="Model 1",caption="")
B=bootVPC(origdata,simdata.F,N_xbin=8)+labs(title="Model 2",caption="")
grid.arrange(A,B,ncol=2)
```

```{r M15, fig.height = 3, fig.width=7.5,fig.cap = "The coverage plots for Model 1 and Model 2."}
A=coverageplot(origdata,simdata.T,conf.level=0.9,N_xbin=8)+labs(title="Model 1")
B=coverageplot(origdata,simdata.F,conf.level=0.9,N_xbin=8)+labs(title="Model 2")
grid.arrange(A,B,ncol=2)
```


Figure \@ref(fig:M15) shows the  `coverageplot` results for Model 1 and Model 2. The lines are in the gray area and close to the white line in Model 1. However, the lines in Model 2 are not in the gray area, especially when the PI value is large. Figures  \@ref(fig:M16) and \@ref(fig:M17) show the results of `coverageDetailplot` for Model 1 and Model 2 when PIs are 50$\%$ and 80$\%$.
The upper and lower percentages in both figures are close to the white points in Model 1. On the other hand, the upper percentages of the most time bins are far from the white points in Model 2, especially the time bin (3.54,5.28] when PI = 50$\%$. When PI = 80$\%$, most upper and lower percentages are far from the white points.


```{r M16,fig.height = 3, fig.width=7.5,fig.cap = "The coverage detailed plots for Model 1 and Model 2 when PI=50%."}
A=coverageDetailplot(origdata,simdata.T,predL=0.5,N_xbin=8)+labs(title="Model 1")
B=coverageDetailplot(origdata,simdata.F,predL=0.5,N_xbin=8)+labs(title="Model 2")
grid.arrange(A,B,ncol=2)
```

```{r M17, fig.height = 3, fig.width=7.5,fig.cap = "The coverage detailed plots for Model 1 and Model 2 when PI=80%."}
A=coverageDetailplot(origdata,simdata.T,predL=0.8,N_xbin=8)+labs(title="Model 1")
B=coverageDetailplot(origdata,simdata.F,predL=0.8,N_xbin=8)+labs(title="Model 2")
grid.arrange(A,B,ncol=2)
```


Figure  \@ref(fig:M18) shows the results of `quantVPC` for Model 1 and Model 2. In Model 2, the right tail area (after 11 hours) looks quite different from the expected pattern. The above percentages are much larger than the below percentages.

The results from Figure  \@ref(fig:M11) through Figure  \@ref(fig:M18) show that Model 1 explains the `origdata` quite well. However, Model 2 shows different patterns than Model 1 in most figures. We can conclude that Model 1 is better than Model 2, and treating $Ka$ and $Cl$ as random effects is better.

```{r M18, fig.height = 3, fig.width=7.5,fig.cap = "The quantified VPC plots for Model 1 and Model 2."}
A=quantVPC(origdata,simdata.T,N_xbin=8)+labs(title="Model 1")
B=quantVPC(origdata,simdata.F,N_xbin=8)+labs(title="Model 2")
grid.arrange(A,B,ncol=2)
```

# Summary

This paper introduces the \pkg{nlmeVPC} package. The VPC and its extensions are useful for validating the nonlinear mixed effect model. The \pkg{nlmeVPC} package provides various visual diagnostic tools for the nonlinear mixed effect model in two different approaches: validation in data space and model space. Both approaches are valuable. Validation in data space can compare the fitted model with the original data, and validation in model space provides detailed comparisons in various ways. In the \pkg{nlmeVPC} package, we also provide new approaches - `asVPC` and `coverageDetailplot`. Here, `asVPC` provides a more precise VPC plot, and `coverageDetailplot` provides the detailed feature of the fitted model that is not captured in the coverage plot. Even though the coverage plot does not show any problem with the fitted model, the coverage detailed plot can reveal the problem in a specific region (Figures \@ref(fig:M14), \@ref(fig:M15), and \@ref(fig:M16)).

# Acknowledgements

This work was supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (2018R1A2B6001251). This paper was prepared by extracting part of Eun-Hwa Kang and Myungji Ko's master thesis.

